# Wise-AIs-Manifesto

Whether we want to or not, the "LLM race" has begun. ChatGPT is best thought of as the starting gun of this race. Market forces will dictate that soon every large tech company will make substantial investments in developing LLMs. We predict a Moore's Law type phenomenon, that LLM capabilities will continue to increase exponentially until they slow down and current methods hit some sort of "glass ceiling".

Current models are trained on truly massive corpora. For example, GPT-3 was trained on the CommonCrawl, which is an open repository of web crawl data.

In some sense, it wouldn't be unreasonable to think of GPT-3 and models of that scale as distillations of humanity's distributed knowledge, within a single "machine".

Decoder-only models like GPT-3 are trained with a next-token prediction objective. That is, they're trained in such a way that given some "context", they're asked to predict the next "token" in a sequence. To make them usable in conversational settings, they have to be "fine-tuned" using conversational data. That is, on datasets where the context explicitly contains conversational content.

There are many examples where models like GPT-3 can suddenly engage in many different personalities. One can speculate that fine-tuning these models can prevent them from falling back into some form of mean-reversion, and help them understand what "mode" they're supposed to engage in. That is, fine-tuning helps them become more aligned to a specific "persona".

So the data we use for fine-tuning these models is actually quite important.

These models are starting to be deployed in roles that would have previously been occupied by humans. For example, as customer service representatives, administrative assistants, etc.

When these models are deployed in these scenarios, it's difficult to do so without some notion of a "personality" being projected onto them. Humans are wired to parse human-like entities as having personalities and motivations. Indeed, it might be inevitable that these chatbots get imbued with some sort of personality.

It also seems inevitable that these chatbots will ultimately be asked to form opinions and make decisions in the real world. In a broad sense, all normative guidance can be said to be rooted in some hierarchy of values. The hierarchy part comes in when there are conflicting values or when some values are considered more important than others. For example, in medical ethics, the value of preserving life is often considered paramount, but it must sometimes be balanced against other values such as patient autonomy and quality of life.

Even in the way these models are trained, they're implicitly trained on human preferences and values. For example, in the InstructGPT paper, they perform a procedure called Reinforcement Learning from Human Feedback (RLHF), where human preferences from side-by-side examples are collected to train the model.

If we're going to deploy models that are human-like, why not explicitly design them to emulate the qualities we as a society hold in the highest regard? That is, why not explicitly design models that are as wise and compassionate as possible as technologically feasible?

Not only would this be good for the world, it would be deeply commercially valuable for companies that buy into this vision. Imagine the wisest and most compassionate person you've ever met. What would it be like if for a day, they worked as a customer service representative. Now what if you could somehow put that person inside a box, and scale them across all customer service interactions in your business, with no loss of quality? That would likely substantially improve your customer satisfaction. What sort of impact would that have on your bottom line?

Instead of merely automating these roles, what if we automated them in such a way that our society was inundated with compassion and wisdom?

Instead of technology divorcing us from other people, we have the opportunity to build truly "humane" technology.

As a society, the genie is out of the bottle. We're on the pathway towards the collective development of a superintelligent artificial intelligence. But we're not passive observers. How we choose to show up in the world, day in and day out, has a direct impact on what will ultimately get developed. Because you see, these models learn from the aggregated preferences of society. They learn from us. What if we used them to amplify the best in us? Instead of merely inundating us in hallucinated bullshit?

It seems that we have the opportunity to shepherd society towards the development of truly enlightened beings, or amoral and neutral commercial optimizers, or something very far on the other side of the spectrum.

As a start, we want to propose the creation of a non for profit, open source framework to train all these LLM application toward enlightened LLMs.
- a UI/UX guideline
- a dataset from the wisest human beings that can be used to perform reinforcement learning to any LLM application 
- a framework to fine-tune enlightened LLMs


[![Watch the video](https://youtu.be/bDttLQBbpbo)](https://youtu.be/bDttLQBbpbo)
