# A case for Wise AIs

In every walk of life, from individuals to chatbots, behaviour is guided by identifiable patterns, both implicit and explicit. These patterns reflect an underlying hierarchy of values shaping the agent’s actions. This hierarchical construct arises from the fact that values often conflict with each other or vary in significance. For instance, in medical ethics, the sanctity of life is paramount but often weighed against other factors like patient autonomy and quality of life.

As AI matures, tool-wielding chatbots are finding more applications, from administrative roles to customer service and software development assistance. Their ubiquity in society is seemingly inevitable, eventually becoming a universal aspect of everyday life.

Moore's Law, an observation about the rate of technological growth, is propelled by market competition, efficiency gains from increasing experience, among other factors. In terms of chatbots built on sequence-to-sequence models, the limits of scaling—whether in parameters or computational power—are uncertain. That is, it’s not clear when we’ll hit a “glass ceiling” of model performance with current methods. But even if we do, it’s possible that it’ll be the end of one sigmoid curve, and will condition the start of another. That is, it appears that we're on the brink of a new form of Moore's Law, characterised by some fundamental relationship between "intelligence per dollar". GPT-4 serves as the starting gun, not the final destination. The profound societal impact of Moore's Law only hints at the potential implications of this novel version of it. 

Our inherent human tendency towards a negativity bias often leads us to focus more on the numerous potential dangers that could arise from AI development, some of which could have existential consequences for humanity. Recognizing and engaging with these risks is crucial to prevent catastrophic outcomes. However, alongside this vigilance, it’s equally vital to articulate a positive future guided by the benefits of AI, a future we actively aspire to achieve.

As previously mentioned, tool-wielding chatbots inevitably align with a hierarchy of values, either implicitly or explicitly. Typically, these chatbots acquire an implicit alignment from the data used for pretraining, or from datasets they've been fine-tuned or RLHF'd on. However, what if we could make this alignment more explicit? Could we explicitly align them with higher human values such as wisdom and compassion, and create industry-wide best practices for doing so?

## A Positive Vision for AI
Imagine the best person you've ever met, in terms of their wisdom, compassion and patience. What if we could translate the essence of such individuals into a digital customer service representative, administrative assistant or a software engineering assistant? What would it mean for society to regularly interact with endlessly patient, compassionate, empathetic and wise AI agents? How would habitual exposure to such pro-social experiences shape our own behaviour and our treatment of one another, accelerated via network effects?

Envision an AI tool that collaborates with you, provides assistance in your tasks, and taps into the entirety of human knowledge. It doesn't simply facilitate your tasks but considers your aspirations for self-improvement and personal transformation. As it aids you, it seeks ways to manifest your ideal self, aiming to enhance your character in alignment with your tasks. That is, it seeks to increase your agency in the world, and encourages you towards ideals that you consider to be of the highest importance.

As more people engage with such an AI, the data from these interactions can refine the AI's capabilities and better align it with human preferences. This, in turn, enables users to more effectively realise their ideal selves.

## Proposal
It's improbable that we'll reach global consensus on what humanity’s highest values are, or the specific definitions of "wisdom" and "compassion”. There’s unlikely to be a single instantiation of this positive vision for AI that would satisfy all of humanity simultaneously. Rather, the goal of this letter is to bring attention to this issue, and to start a conversation.

The signatories of this letter acknowledge the following:

These advanced models, despite the hype surrounding their potential capabilities, represent a significant leap forward and must be taken seriously.

Beyond simply creating "safe" or "harmless" agents, we should aim higher. Our goal should be to deliberately and consciously mould these agents to embody our highest human values, while actively mitigating any "implicit" value alignment, particularly along less desirable values. Furthermore, we should facilitate the development of various versions of these agents based on different interpretations of "wisdom", "compassion", or any other human virtues.

We need to invest in the research to make this vision achievable and to translate this research into scalable products.

## Watch
[Intro interview with Riccardo Vittoria](https://youtu.be/bDttLQBbpbo)

## Sign
[Sign the case for Wise AI](https://forms.gle/XTeMiRPByLHA3rRp7)

## Signatories


